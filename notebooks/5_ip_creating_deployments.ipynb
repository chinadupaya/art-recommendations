{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Local environment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/decodingml/hands-on-recommender-system.git\n",
    "    %cd hands-on-recommender-system/\n",
    "\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"‚õ≥Ô∏è Google Colab environment\")\n",
    "else:\n",
    "    root_dir = str(Path().absolute().parent)\n",
    "    print(\"‚õ≥Ô∏è Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    print(f\"Adding the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference pipeline: Deploying and testing the inference pipeline \n",
    "\n",
    "In this notebook, we will dig into the inference pipeline and deploy it to Hopsworks as a real-time service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from recsys import hopsworks_integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-01 02:29:14.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecsys.hopsworks_integration.feature_store\u001b[0m:\u001b[36mget_feature_store\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mLoging to Hopsworks using HOPSWORKS_API_KEY env var.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-01 02:29:14,822 INFO: Initializing external client\n",
      "2025-01-01 02:29:14,823 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-01 02:29:16,380 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1197208\n"
     ]
    }
   ],
   "source": [
    "project, fs = hopsworks_integration.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the ranking inference pipeline\n",
    "You start by deploying your ranking model. Since it is a CatBoost model you need to implement a `Predict` class that tells Hopsworks how to load the model and how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4427/4427 elapsed<00:02 remaining<00:00\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1113/1113 elapsed<00:01 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://c.app.hopsworks.ai:443/p/1197208/deployments/353350\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment = hopsworks_integration.ranking_serving.HopsworksRankingModel.deploy(\n",
    "    project=project\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to explicitly start the deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is ready: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:26<00:00,  4.41s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check logs in case of failure\n",
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> Test the ranking inference pipeline</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get Hopsworks Model Serving\n",
    "ms = project.get_model_serving()\n",
    "\n",
    "# get deployment object\n",
    "query_model_deployment = ms.get_deployment(\"query\")\n",
    "# get Hopsworks Model Registry\n",
    "mr = project.get_model_registry()\n",
    "  \n",
    "# get model\n",
    "model = mr.get_model(query_model_deployment.model_name, query_model_deployment.model_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(ranked_candidates, k=3):\n",
    "    return [candidate[-1] for candidate in ranked_candidates[\"ranking\"][:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a dummy test example to test our ranking deployment (only the `user_id` has to match):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['515d04725eeb1c524c0020f4',\n",
       " '516c96a30f8b7850670001ee',\n",
       " '515b6eb41b12b0244a000661']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranking_input = [\n",
    "        {\n",
    "            \"user_id\": \"a926fcb4-fcb9-461c-bcf3-94e99087488a\",\n",
    "            \"query_emb\": [-0.055558718740940094, \n",
    "            0.265354186296463,0.14594393968582153, \n",
    "            0.5653434991836548, 0.02886250615119934, \n",
    "            0.06645234674215317, -0.11563731729984283, \n",
    "            -0.11164169758558273, 0.03345891833305359, \n",
    "            -0.1873944103717804, -0.23655693233013153, \n",
    "            -0.2209630161523819, -0.04303218796849251, \n",
    "            0.05191042274236679, -0.13368633389472961, 0.011423708871006966]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = ranking_deployment.predict(inputs=test_ranking_input)\n",
    "\n",
    "# Retrieve artwork ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check logs in case of failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/1197208/deployments/353350\n",
      "\n",
      "DeployableComponentLogs(instance_name: 'ranking-transformer-00001-deployment-f97cb5bbf-p5h76', date: datetime.datetime(2025, 1, 1, 2, 30, 34, 787575)) \n",
      "INFO:root:Loading component module...\n",
      "INFO:root:[TransformerModel] Initializing transformer for model: ranking\n",
      "INFO:root:[HopsworksModel] Initializing for model: ranking\n",
      "INFO:hsfs.engine.python:Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai/p/1197208\n",
      "... execution time: 7.677094 seconds\n",
      "INFO:root:Starting KServe server...\n",
      "2025-01-01 01:30:02.215 8 kserve INFO [model_server.py:register_model():363] Registering model: ranking\n",
      "2025-01-01 01:30:02.216 8 kserve INFO [model_server.py:start():298] Setting max asyncio worker threads as 12\n",
      "2025-01-01 01:30:02.216 8 kserve INFO [model_server.py:_serve_rest():244] Starting uvicorn with 1 workers\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.legacy is deprecated; see https://websockets.readthedocs.io/en/stable/howto/upgrade.html for upgrade instructions\n",
      "\n",
      "WARNING:py.warnings:DeprecationWarning: websockets.server.WebSocketServerProtocol is deprecated\n",
      "\n",
      "2025-01-01 01:30:02.251 uvicorn.error INFO:     Started server process [8]\n",
      "2025-01-01 01:30:02.251 uvicorn.error INFO:     Waiting for application startup.\n",
      "2025-01-01 01:30:02.254 8 kserve INFO [server.py:start():68] Starting gRPC server on [::]:8081\n",
      "2025-01-01 01:30:02.254 uvicorn.error INFO:     Application startup complete.\n",
      "2025-01-01 01:30:02.254 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)\n",
      "2025-01-01 01:30:27.875 uvicorn.access INFO:     127.0.0.1:42344 8 - \"GET /metrics HTTP/1.1\" 200 OK\n",
      "2025-01-01 01:30:27.875 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0007429122924804688 ['http_status:200', 'http_method:GET', 'time:wall']\n",
      "2025-01-01 01:30:27.875 kserve.trace kserve.io.kserve.protocol.rest.server.metrics_handler: 0.0007330000000003167 ['http_status:200', 'http_method:GET', 'time:cpu']\n",
      "INFO:root:Received request via 'v1 protocol'\n",
      "WARNING:py.warnings:VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "\n",
      "WARNING:py.warnings:DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.\n",
      "\n",
      "WARNING:opensearch:POST https://rest.elastic.service.consul:9200/1197208__embedding_default_project_embedding_0/_search?timeout=30s [status:400 request:0.002s]\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.36s) \n",
      "WARNING:py.warnings:VersionWarning: No training dataset version was provided to initialise serving. Defaulting to version 1.\n",
      "\n",
      "INFO:root:‚úÖ artworks Data Retrieved!\n",
      "INFO:root:‚úÖ Inputs are almost ready!\n",
      "INFO:root:‚úÖ Inputs are ready!\n",
      "2025-01-01 01:30:30.913 kserve.trace requestId: 658f3fd2-d513-4508-8135-15ee44809b9e, preprocess_ms: 2767.110347748, explain_ms: 0, predict_ms: 25.55847168, postprocess_ms: 0.094413757\n",
      "2025-01-01 01:30:30.914 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 2.7938790321350098 ['http_status:200', 'http_method:POST', 'time:wall']\n",
      "2025-01-01 01:30:30.914 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.13546699999999978 ['http_status:200', 'http_method:POST', 'time:cpu']\n",
      "INFO:httpx:HTTP Request: POST http://ranking-predictor.id2223artsy/v1/models/ranking:predict \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Received response via 'v1 protocol'\n",
      "INFO:root:‚úÖ Predictions are ready!\n",
      "2025-01-01 01:30:30.913 uvicorn.access INFO:     10.2.3.34:0 8 - \"POST /v1/models/ranking%3Apredict HTTP/1.1\" 200 OK\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.get_logs(component=\"transformer\", tail=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying the query inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2471/2471 elapsed<00:01 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created, explore it at https://c.app.hopsworks.ai:443/p/1197208/deployments/353351\n",
      "Before making predictions, start the deployment by using `.start()`\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment = (\n",
    "    hopsworks_integration.two_tower_serving.HopsworksQueryModel.deploy(project=project)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is ready: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:26<00:00,  4.45s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making predictions by using `.predict()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query_model_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore all the logs and filters in the Kibana logs at https://c.app.hopsworks.ai:443/p/1197208/deployments/352324\n",
      "\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1197208/serving/352324/logs). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":240027,\"errorMsg\":\"Server logs not available\"}', error code: 240027, error msg: Server logs not available, user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check logs in case of failure\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mquery_model_deployment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/art-recommendations/.venv/lib/python3.11/site-packages/hsml/deployment.py:248\u001b[0m, in \u001b[0;36mDeployment.get_logs\u001b[0;34m(self, component, tail)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m component \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m components:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComponent \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not valid. Possible values are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    244\u001b[0m             component, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(components)\n\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m     )\n\u001b[0;32m--> 248\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serving_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m logs:\n",
      "File \u001b[0;32m~/Documents/code/art-recommendations/.venv/lib/python3.11/site-packages/hsml/engine/serving_engine.py:555\u001b[0m, in \u001b[0;36mServingEngine.get_logs\u001b[0;34m(self, deployment_instance, component, tail)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment is starting, server logs might not be ready yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplore all the logs and filters in the Kibana logs at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;241m+\u001b[39m deployment_instance\u001b[38;5;241m.\u001b[39mget_url(),\n\u001b[1;32m    552\u001b[0m     end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    553\u001b[0m )\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serving_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/art-recommendations/.venv/lib/python3.11/site-packages/hsml/core/serving_api.py:404\u001b[0m, in \u001b[0;36mServingApi.get_logs\u001b[0;34m(self, deployment_instance, component, tail)\u001b[0m\n\u001b[1;32m    395\u001b[0m path_params \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m     _client\u001b[38;5;241m.\u001b[39m_project_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m ]\n\u001b[1;32m    402\u001b[0m query_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponent\u001b[39m\u001b[38;5;124m\"\u001b[39m: component, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail\u001b[39m\u001b[38;5;124m\"\u001b[39m: tail}\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deployable_component_logs\u001b[38;5;241m.\u001b[39mDeployableComponentLogs\u001b[38;5;241m.\u001b[39mfrom_response_json(\n\u001b[0;32m--> 404\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/code/art-recommendations/.venv/lib/python3.11/site-packages/hopsworks_common/decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/art-recommendations/.venv/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[1;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[1;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1197208/serving/352324/logs). Server response: \nHTTP code: 404, HTTP reason: Not Found, body: b'{\"errorCode\":240027,\"errorMsg\":\"Server logs not available\"}', error code: 240027, error msg: Server logs not available, user msg: "
     ]
    }
   ],
   "source": [
    "# Check logs in case of failure\n",
    "query_model_deployment.get_logs(component=\"transformer\", tail=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['515b0c7005635113a5000681',\n",
       " '515b84b894714c2e3800018f',\n",
       " '515d469ab5907bf7e8003d89']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranking_input = [\n",
    "    {\n",
    "        \"user_id\": \"a926fcb4-fcb9-461c-bcf3-94e99087488a\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test ranking deployment\n",
    "ranked_candidates = query_model_deployment.predict(inputs=test_ranking_input)\n",
    "\n",
    "# Retrieve artwork ids of the top recommended items\n",
    "recommendations = get_top_recommendations(ranked_candidates[\"predictions\"], k=3)\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\"> Stopping the Hopsworks deployments </span>\n",
    "Stop the deployment when you're not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment is stopped: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.74s/it]       \n",
      "Deployment is stopped: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:10<00:00,  2.66s/it]        \n"
     ]
    }
   ],
   "source": [
    "ranking_deployment.stop()\n",
    "query_model_deployment.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
